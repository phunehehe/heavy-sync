#!/usr/bin/env python
# coding=utf-8
# This module deliberately does not reuse code from heavy-sync.

import argparse
import boto
import codecs
import locale
import hashlib
import random
import sys
import tempfile

# Seemingly unused but needed for GCS authentication
import gcs_oauth2_boto_plugin

# Wrap sys.stdout to allow writing Unicode to a pipe
# http://stackoverflow.com/a/4546129/168034
sys.stdout = codecs.getwriter(locale.getpreferredencoding())(sys.stdout)


# Work around https://github.com/boto/boto/issues/2836
import ssl

_old_match_hostname = ssl.match_hostname

def _new_match_hostname(cert, hostname):
   if hostname.endswith('.s3.amazonaws.com'):
      pos = hostname.find('.s3.amazonaws.com')
      hostname = hostname[:pos].replace('.', '') + hostname[pos:]
   return _old_match_hostname(cert, hostname)

ssl.match_hostname = _new_match_hostname


LOWER_POOL_LIMIT = 10
UPPER_POOL_LIMIT = 100


def random_add(item, pool, probability):
    if random.random() < probability:
        pool.append(item)


def handle_pool(item, pool, probability):

    length = len(pool)

    if length < UPPER_POOL_LIMIT:
        random_add(item, pool, probability)
    else:
        pool = random.sample(pool, LOWER_POOL_LIMIT)
        probability = probability * LOWER_POOL_LIMIT / UPPER_POOL_LIMIT
        random_add(item, pool, probability)

    return pool, probability


def get_bucket(scheme, bucket_name):
    connection = {
        'gs': boto.connect_gs,
        's3': boto.connect_s3,
    }[scheme]()
    return connection.get_bucket(bucket_name)


def choose_target(bucket, folder):

    pool = []
    probability = 1.0

    for key in bucket.list(prefix=folder):
        # Skip folders
        if key.name[-1] == '/':
            continue
        pool, probability = handle_pool((key.name, key.etag), pool, probability)

    assert pool, '%s/%s is empty!' % (bucket, folder)
    return random.choice(pool)


def break_uri(uri):
    # scheme://bucket-name/sub/folder -> (scheme, bucket-name, /sub/folder)
    parts = uri.split('/')
    scheme = parts[0].split(':')[0]
    bucket_name = parts[2]
    folder = '/'.join(parts[3:])
    return (scheme, bucket_name, folder)


def main():

    parser = argparse.ArgumentParser()
    parser.add_argument('source')
    parser.add_argument('destination')
    args = parser.parse_args()

    s_scheme, s_bucket_name, folder = break_uri(args.source)
    d_scheme, d_bucket_name, _      = break_uri(args.destination)

    s_bucket = get_bucket(s_scheme, s_bucket_name)
    d_bucket = get_bucket(d_scheme, d_bucket_name)

    name, s_etag = choose_target(s_bucket, folder)

    key = d_bucket.get_key(name)
    assert key, '%s://%s/%s must exist!' % (d_scheme, d_bucket_name, name)

    # Roll over when hitting 10 MB
    f = tempfile.SpooledTemporaryFile(max_size=10*2**20)
    key.get_contents_to_file(f)
    # Go back to the beginning of the file before reading
    f.seek(0)
    real_md5 = hashlib.md5(f.read()).hexdigest()
    # For some reason s_etag contains double quotes around the hash
    assert real_md5 in s_etag, 'Hash of %s://%s/%s must be %s!' % (
        d_scheme, d_bucket_name, name, s_etag)

    print 'Checked file %s://%s/%s against %s://%s. MD5 %s. OK.' % (
        s_scheme, s_bucket_name, name, d_scheme, d_bucket_name, real_md5)


main()
